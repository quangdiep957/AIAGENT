# agents.py
import os
from langchain_openai import ChatOpenAI
from langchain.agents import initialize_agent, AgentType
from langchain.tools import tool
from typing import List, Dict, Any, Optional
import json
from datetime import datetime

# Import cÃ¡c tools hiá»‡n cÃ³
from tools import FileUploadTool, FileReaderTool, OCRTool, EmbeddingTool, VectorSearchTool
from tools import save_chat_content, get_chat_history_summary, search_chat_and_documents, auto_save_english_content
from tools import search_web_with_evaluation, generate_llm_response_for_query
from services import EmbeddingService
from database import DatabaseManager

# Khá»Ÿi táº¡o cÃ¡c tools
upload_tool = FileUploadTool(upload_dir="uploads")
reader_tool = FileReaderTool()
ocr_tool = OCRTool()
embedding_tool = EmbeddingTool()
search_tool = VectorSearchTool()
embedding_service = EmbeddingService()
db_manager = DatabaseManager()

@tool
def upload_and_process_document(file_info: str) -> str:
    """
    Upload vÃ  xá»­ lÃ½ tÃ i liá»‡u (PDF, Word, Image) Ä‘á»ƒ lÆ°u vÃ o database vÃ  táº¡o embeddings
    
    Args:
        file_info: ThÃ´ng tin file dáº¡ng "file_path|file_name" (vÃ­ dá»¥: "/path/to/file.pdf|document.pdf")
    
    Returns:
        Káº¿t quáº£ xá»­ lÃ½ file
    """
    try:
        print(f"ðŸ” DEBUG: Starting upload process with input: {file_info}")
        
        # Parse file info
        if "|" not in file_info:
            print(f"âŒ DEBUG: Invalid format - missing | separator")
            return "âŒ Format khÃ´ng Ä‘Ãºng. Vui lÃ²ng sá»­ dá»¥ng format: file_path|file_name"
        
        file_path, file_name = file_info.split("|", 1)
        print(f"ðŸ” DEBUG: Parsed - file_path: {file_path}, file_name: {file_name}")
        
        # Check file exists
        if not os.path.exists(file_path):
            print(f"âŒ DEBUG: File not found at path: {file_path}")
            return f"âŒ File khÃ´ng tá»“n táº¡i: {file_path}"
        
        print(f"ðŸ” DEBUG: File size: {os.path.getsize(file_path):,} bytes")
        
        # Upload file
        print(f"ðŸ” DEBUG: Starting file upload...")
        upload_result = upload_tool.upload_file(
            file_path=file_path,
            metadata={
                "original_name": file_name,
                "upload_source": "ai_agent"
            }
        )
        
        print(f"ðŸ” DEBUG: Upload result success: {upload_result.get('success')}")
        if not upload_result["success"]:
            error_msg = f"âŒ Upload tháº¥t báº¡i: {', '.join(upload_result.get('errors', ['Unknown error']))}"
            print(f"âŒ DEBUG: {error_msg}")
            return error_msg
        
        file_document = upload_result["document"]
        file_id = upload_result["file_id"]
        print(f"ðŸ” DEBUG: Upload successful - file_id: {file_id}")
        
        # Extract content dá»±a trÃªn loáº¡i file
        content = ""
        extraction_method = ""
        file_type = file_document["file_type"]
        file_path_abs = file_document["absolute_path"]
        
        print(f"ðŸ” DEBUG: File type detected: {file_type}")
        print(f"ðŸ” DEBUG: Absolute path: {file_path_abs}")
        
        if file_type in ["pdf", "docx", "doc", "txt", "md", "text"]:
            # Äá»c file text-based
            print(f"ðŸ” DEBUG: Reading {file_type} file...")
            read_result = reader_tool.read_file(file_path_abs)
            print(f"ðŸ” DEBUG: Read result success: {read_result.get('success')}")
            
            if read_result["success"]:
                if file_type == "pdf":
                    content = read_result.get("total_content", read_result.get("content", ""))
                elif file_type in ["docx", "doc"]:
                    content = read_result.get("total_content", read_result.get("content", ""))
                else:  # text files
                    content = read_result["content"]
                extraction_method = "file_reader"
                print(f"ðŸ” DEBUG: Content extracted - length: {len(content)} chars")
            else:
                error_msg = f"âŒ KhÃ´ng thá»ƒ Ä‘á»c file: {read_result.get('error', 'Unknown read error')}"
                print(f"âŒ DEBUG: {error_msg}")
                return error_msg
        
        elif file_type == "image":
            # OCR cho áº£nh
            print(f"ðŸ” DEBUG: Processing image with OCR...")
            ocr_result = ocr_tool.extract_text_from_image(file_path_abs)
            print(f"ðŸ” DEBUG: OCR result success: {ocr_result.get('success')}")
            
            if ocr_result["success"]:
                content = ocr_result["text"]
                extraction_method = "ocr"
                print(f"ðŸ” DEBUG: OCR content extracted - length: {len(content)} chars")
            else:
                error_msg = f"âŒ OCR tháº¥t báº¡i: {ocr_result.get('error', 'Unknown OCR error')}"
                print(f"âŒ DEBUG: {error_msg}")
                return error_msg
        else:
            error_msg = f"âŒ Loáº¡i file khÃ´ng Ä‘Æ°á»£c há»— trá»£: {file_type}"
            print(f"âŒ DEBUG: {error_msg}")
            return error_msg
        
        if not content or not content.strip():
            print(f"âŒ DEBUG: Empty content after extraction")
            return "âŒ KhÃ´ng thá»ƒ trÃ­ch xuáº¥t ná»™i dung tá»« file"
        
        print(f"ðŸ” DEBUG: Content validation passed - {len(content.split())} words")
        
        # Táº¡o embeddings
        print(f"ðŸ” DEBUG: Creating embeddings...")
        processing_result = embedding_service.process_file_content(
            file_id=file_id,
            content=content,
            metadata={
                "extraction_method": extraction_method,
                "file_type": file_type
            }
        )
        
        print(f"ðŸ” DEBUG: Embedding result success: {processing_result.get('success')}")
        
        if not processing_result["success"]:
            error_msg = f"âŒ Táº¡o embedding tháº¥t báº¡i: {processing_result.get('error', 'Unknown embedding error')}"
            print(f"âŒ DEBUG: {error_msg}")
            return error_msg
        
        print(f"ðŸ” DEBUG: Processing completed successfully!")
        success_msg = f"""âœ… ÄÃ£ xá»­ lÃ½ thÃ nh cÃ´ng file: {file_name}
ðŸ“Š ThÃ´ng tin:
- Loáº¡i file: {file_type.upper()}
- Sá»‘ tá»«: {len(content.split()):,}
- Chá»§ Ä‘á»: {processing_result.get('topic', 'N/A')}
- Äá»™ khÃ³: {processing_result.get('difficulty_level', 'N/A')}
- Sá»‘ chunks: {processing_result.get('total_chunks', 'N/A')}
- Tags: {', '.join(processing_result.get('tags', []))}

TÃ i liá»‡u Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o database vÃ  sáºµn sÃ ng Ä‘á»ƒ tÃ¬m kiáº¿m!"""
        print(f"ðŸ” DEBUG: Returning success message")
        return success_msg
        
    except Exception as e:
        error_msg = f"âŒ Lá»—i xá»­ lÃ½ file: {str(e)}"
        print(f"âŒ DEBUG: Exception occurred: {error_msg}")
        import traceback
        print(f"âŒ DEBUG: Traceback: {traceback.format_exc()}")
        return error_msg

@tool
def search_documents(query: str) -> str:
    """
    TÃ¬m kiáº¿m tÃ i liá»‡u dá»±a trÃªn ná»™i dung cÃ¢u há»i
    
    Args:
        query: CÃ¢u há»i hoáº·c tá»« khÃ³a cáº§n tÃ¬m
    
    Returns:
        Ná»™i dung tÃ i liá»‡u liÃªn quan Ä‘Æ°á»£c tÃ¬m tháº¥y
    """
    try:
        limit = 3  # Set default limit
        search_result = search_tool.similarity_search(
            query_text=query,
            limit=limit,
            similarity_threshold=0.3
        )
        
        if not search_result["success"]:
            return f"âŒ Lá»—i tÃ¬m kiáº¿m: {search_result['error']}"
        
        if not search_result["results"]:
            return "ðŸ” KhÃ´ng tÃ¬m tháº¥y tÃ i liá»‡u nÃ o liÃªn quan Ä‘áº¿n cÃ¢u há»i nÃ y. Báº¡n cÃ³ thá»ƒ upload thÃªm tÃ i liá»‡u Ä‘á»ƒ tÃ´i há»— trá»£ tá»‘t hÆ¡n."
        
        # Format káº¿t quáº£ tÃ¬m kiáº¿m
        results = []
        for i, doc in enumerate(search_result["results"], 1):
            # Giá»¯ nguyÃªn ná»™i dung tiáº¿ng Anh, chá»‰ thÃªm thÃ´ng tin metadata báº±ng tiáº¿ng Viá»‡t
            content_preview = doc['content'][:500]
            if len(doc['content']) > 500:
                content_preview += "..."
            
            results.append(f"""
ðŸ“„ **TÃ i liá»‡u {i}** (Äá»™ tÆ°Æ¡ng Ä‘á»“ng: {doc['similarity_score']:.2f})
ðŸ“š Chá»§ Ä‘á»: {doc.get('topic', 'N/A')}
ðŸ“ Ná»™i dung: {content_preview}
""")
        
        return f"""ðŸ” **TÃ¬m tháº¥y {len(search_result['results'])} tÃ i liá»‡u liÃªn quan:**

{''.join(results)}

ðŸ’¡ Dá»±a trÃªn nhá»¯ng tÃ i liá»‡u tiáº¿ng Anh trÃªn, tÃ´i cÃ³ thá»ƒ giÃºp báº¡n há»c táº­p hiá»‡u quáº£."""
        
    except Exception as e:
        return f"âŒ Lá»—i tÃ¬m kiáº¿m: {str(e)}"

@tool
def get_document_summary(dummy_input: str = "") -> str:
    """
    Láº¥y tÃ³m táº¯t vá» cÃ¡c tÃ i liá»‡u Ä‘Ã£ upload trong database
    
    Args:
        dummy_input: Tham sá»‘ khÃ´ng sá»­ dá»¥ng (Ä‘á»ƒ Ä‘áº£m báº£o single input)
    
    Returns:
        Thá»‘ng kÃª tÃ i liá»‡u trong database
    """
    try:
        collections = db_manager.get_collections()
        
        if "document_embeddings" in collections:
            collection = db_manager.db["document_embeddings"]
            total_docs = collection.count_documents({})
            
            # Láº¥y thá»‘ng kÃª theo chá»§ Ä‘á»
            pipeline = [
                {"$group": {"_id": "$topic", "count": {"$sum": 1}}},
                {"$sort": {"count": -1}},
                {"$limit": 5}
            ]
            topics = list(collection.aggregate(pipeline))
            
            topic_summary = "\n".join([f"- {topic['_id']}: {topic['count']} tÃ i liá»‡u" for topic in topics])
            
            return f"""ðŸ“Š **Thá»‘ng kÃª tÃ i liá»‡u trong database:**

ðŸ“š Tá»•ng sá»‘ tÃ i liá»‡u: {total_docs}

ðŸ” **Top chá»§ Ä‘á»:**
{topic_summary}

ðŸ’¡ Báº¡n cÃ³ thá»ƒ há»i tÃ´i vá» báº¥t ká»³ chá»§ Ä‘á» nÃ o trong danh sÃ¡ch trÃªn!"""
        else:
            return "ðŸ“š ChÆ°a cÃ³ tÃ i liá»‡u nÃ o Ä‘Æ°á»£c upload. HÃ£y upload tÃ i liá»‡u Ä‘á»ƒ tÃ´i cÃ³ thá»ƒ há»— trá»£ báº¡n!"
            
    except Exception as e:
        return f"âŒ Lá»—i láº¥y thá»‘ng kÃª: {str(e)}"

@tool
def smart_search_and_answer(query: str) -> str:
    """
    TÃ¬m kiáº¿m thÃ´ng minh vÃ  tráº£ lá»i cÃ¢u há»i theo luá»“ng: Knowledge Base -> Web Search -> LLM Response
    ÄÃ¢y lÃ  tool chÃ­nh cho má»i cÃ¢u há»i tÃ¬m kiáº¿m thÃ´ng tin.
    
    Args:
        query: CÃ¢u há»i hoáº·c tá»« khÃ³a cáº§n tÃ¬m
    
    Returns:
        Káº¿t quáº£ tÃ¬m kiáº¿m vÃ  tráº£ lá»i tá»‘i Æ°u
    """
    try:
        print(f"ðŸ” SMART SEARCH: Starting search for query: {query}")
        
        # BÆ°á»›c 1: TÃ¬m trong Knowledge Base trÆ°á»›c
        print(f"ðŸ” SMART SEARCH: Step 1 - Searching Knowledge Base...")
        kb_results = search_tool.similarity_search(
            query_text=query,
            limit=3,
            similarity_threshold=0.4  # NgÆ°á»¡ng cao hÆ¡n Ä‘á»ƒ Ä‘áº£m báº£o cháº¥t lÆ°á»£ng
        )
        
        if kb_results["success"] and kb_results["results"]:
            # CÃ³ káº¿t quáº£ trong KB, Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng
            best_score = max(result['similarity_score'] for result in kb_results["results"])
            print(f"ðŸ” SMART SEARCH: KB found {len(kb_results['results'])} results, best score: {best_score:.3f}")
            
            # Kiá»ƒm tra Ä‘á»™ relevance thá»±c sá»± báº±ng cÃ¡ch xem content cÃ³ liÃªn quan khÃ´ng
            best_result = max(kb_results["results"], key=lambda x: x['similarity_score'])
            content_sample = best_result['content'][:200].lower()
            query_lower = query.lower()
            
            # Tá»« khÃ³a relevance check
            relevant_keywords = False
            query_words = set(query_lower.split())
            content_words = set(content_sample.split())
            overlap = len(query_words.intersection(content_words))
            
            if overlap >= 2 or best_score >= 0.7:  # TÄƒng threshold cho KB
                relevant_keywords = True
                
            print(f"ðŸ” SMART SEARCH: Relevance check - overlap: {overlap}, relevant: {relevant_keywords}")
            
            if best_score >= 0.7 and relevant_keywords:  # TÄƒng threshold tá»« 0.6 lÃªn 0.7
                print(f"âœ… SMART SEARCH: Using Knowledge Base results (high quality)")
                results_text = []
                for i, doc in enumerate(kb_results["results"], 1):
                    content_preview = doc['content'][:400] + "..." if len(doc['content']) > 400 else doc['content']
                    results_text.append(f"""
ðŸ“„ **TÃ i liá»‡u {i}** (Äá»™ tÆ°Æ¡ng Ä‘á»“ng: {doc['similarity_score']:.2f})
ðŸ“š Chá»§ Ä‘á»: {doc.get('topic', 'N/A')}
ðŸ“ Ná»™i dung: {content_preview}
""")
                
                return f"""âœ… **TÃ¬m tháº¥y trong Knowledge Base**

ðŸ” **TÃ¬m tháº¥y {len(kb_results['results'])} tÃ i liá»‡u liÃªn quan:**

{''.join(results_text)}

ðŸ’¡ **Nguá»“n:** Knowledge Base cháº¥t lÆ°á»£ng cao
**Äá»™ tin cáº­y:** Cao"""
        
        # BÆ°á»›c 2: KB khÃ´ng cÃ³ hoáº·c cháº¥t lÆ°á»£ng tháº¥p -> TÃ¬m kiáº¿m web
        print(f"ðŸ” SMART SEARCH: Step 2 - KB insufficient, searching web...")
        from tools.web_search_tool import search_web_with_evaluation, generate_llm_response_for_query
        web_result = search_web_with_evaluation(query)
        
        print(f"ðŸ” SMART SEARCH: Web search completed")
        
        if "search_results_ready" in web_result:
            print(f"âœ… SMART SEARCH: Using web search results")
            return web_result
        elif "llm_response_needed" in web_result:
            # BÆ°á»›c 3: Web search khÃ´ng tá»‘t -> DÃ¹ng LLM
            print(f"ðŸ” SMART SEARCH: Step 3 - Web insufficient, using LLM fallback...")
            llm_response = generate_llm_response_for_query(query)
            print(f"âœ… SMART SEARCH: Using LLM fallback response")
            return llm_response
        else:
            # Fallback
            print(f"âœ… SMART SEARCH: Using web result as fallback")
            return web_result
            
    except Exception as e:
        # Final fallback
        print(f"âŒ SMART SEARCH: Exception occurred: {str(e)}")
        from tools.web_search_tool import generate_llm_response_for_query
        llm_response = generate_llm_response_for_query(query)
        return f"""âš ï¸ **Lá»—i trong quÃ¡ trÃ¬nh tÃ¬m kiáº¿m: {str(e)}**

{llm_response}"""

def get_llm():
    """Khá»Ÿi táº¡o ChatOpenAI model"""
    return ChatOpenAI(model="gpt-4.1", temperature=0.3)

def create_agent():
    """Táº¡o AI agent vá»›i cÃ¡c tools tÃ­ch há»£p"""
    llm = get_llm()
    
    # Chá»‰ expose cÃ¡c tools chÃ­nh, áº©n tools phá»¥ Ä‘á»ƒ agent khÃ´ng gá»i trá»±c tiáº¿p
    tools = [
        upload_and_process_document,
        smart_search_and_answer,  # Tool chÃ­nh cho search - sáº½ handle KB -> Web -> LLM internally
        get_document_summary
    ]

    # Táº¡o agent Ä‘Æ¡n giáº£n vá»›i ReAct
    agent = initialize_agent(
        tools,
        llm,
        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
        verbose=False,
        handle_parsing_errors=True
    )
    return agent
