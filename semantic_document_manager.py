#!/usr/bin/env python3
"""
Semantic Document Manager - Qu·∫£n l√Ω documents v·ªõi semantic search s·ª≠ d·ª•ng OpenAI embeddings
"""

from pymongo import MongoClient
from config import MONGODB_CONNECTION, OPENAI_API_KEY
import logging
from langchain_openai import OpenAIEmbeddings
import numpy as np

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SemanticDocumentManager:
    """
    Qu·∫£n l√Ω documents v·ªõi semantic search s·ª≠ d·ª•ng OpenAI embeddings
    
    T√≠nh nƒÉng ch√≠nh:
    - L∆∞u tr·ªØ documents v·ªõi embeddings
    - T√¨m ki·∫øm semantic s·ª≠ d·ª•ng cosine similarity
    - Qu·∫£n l√Ω documents theo user
    - CRUD operations ƒë·∫ßy ƒë·ªß
    """
    
    def __init__(self, database_name="study_db", collection_name="documents"):
        """
        Kh·ªüi t·∫°o semantic document manager
        
        Args:
            database_name (str): T√™n database
            collection_name (str): T√™n collection cho documents
        """
        self.client = None
        self.db = None
        self.collection = None
        self.embeddings_model = None
        self.database_name = database_name
        self.collection_name = collection_name
        
        # K·∫øt n·ªëi database v√† setup embeddings
        self.connect()
        self.setup_embeddings()
    
    def connect(self):
        """K·∫øt n·ªëi ƒë·∫øn MongoDB"""
        try:
            # T·∫°o k·∫øt n·ªëi MongoDB
            self.client = MongoClient(MONGODB_CONNECTION)
            
            # Test k·∫øt n·ªëi
            self.client.admin.command('ping')
            logger.info("‚úÖ K·∫øt n·ªëi MongoDB cho semantic search th√†nh c√¥ng!")
            
            # S·ª≠ d·ª•ng database ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh
            self.db = self.client[self.database_name]
            self.collection = self.db[self.collection_name]
            
            # T·∫°o collection n·∫øu ch∆∞a t·ªìn t·∫°i
            if self.collection_name not in self.db.list_collection_names():
                self.db.create_collection(self.collection_name)
                logger.info(f"üìÅ ƒê√£ t·∫°o collection: {self.collection_name}")
            
            logger.info(f"üéØ ƒêang s·ª≠ d·ª•ng database: {self.database_name}, collection: {self.collection_name}")
            
        except Exception as e:
            logger.error(f"‚ùå Kh√¥ng th·ªÉ k·∫øt n·ªëi MongoDB: {e}")
            raise
    
    def setup_embeddings(self):
        """Thi·∫øt l·∫≠p OpenAI embeddings model"""
        try:
            if not OPENAI_API_KEY:
                raise ValueError("Kh√¥ng t√¨m th·∫•y OPENAI_API_KEY trong bi·∫øn m√¥i tr∆∞·ªùng")
            
            # Kh·ªüi t·∫°o model embeddings
            self.embeddings_model = OpenAIEmbeddings(
                model="text-embedding-3-small",
                openai_api_key=OPENAI_API_KEY
            )
            logger.info("‚úÖ OpenAI embeddings model ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng!")
            
        except Exception as e:
            logger.error(f"‚ùå Kh√¥ng th·ªÉ thi·∫øt l·∫≠p embeddings: {e}")
            raise
    
    def save_document(self, user_id, file_name, content, metadata=None):
        """
        L∆∞u document v·ªõi semantic embedding
        
        Args:
            user_id (str): ID c·ªßa user
            file_name (str): T√™n file ƒë∆∞·ª£c upload
            content (str): N·ªôi dung text c·ªßa document
            metadata (dict): Metadata b·ªï sung (t√πy ch·ªçn)
        
        Returns:
            str: ID c·ªßa document n·∫øu th√†nh c√¥ng
        """
        try:
            # T·∫°o embedding cho n·ªôi dung
            embedding = self.embeddings_model.embed_query(content)
            
            # Chu·∫©n b·ªã document
            doc = {
                "user_id": user_id,
                "file_name": file_name,
                "content": content,
                "embedding": embedding,
                "content_length": len(content),
                "created_at": self._get_current_timestamp(),
                "metadata": metadata or {}
            }
            
            # Ch√®n document v√†o database
            result = self.collection.insert_one(doc)
            doc_id = str(result.inserted_id)
            
            logger.info(f"‚úÖ Document ƒë√£ ƒë∆∞·ª£c l∆∞u th√†nh c√¥ng v·ªõi ID: {doc_id}")
            logger.info(f"üìÑ File: {file_name}, ƒê·ªô d√†i n·ªôi dung: {len(content)} k√Ω t·ª±")
            
            return doc_id
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi l∆∞u document: {e}")
            raise
    
    def search_similar(self, query, top_k=3, user_id=None):
        """
        T√¨m ki·∫øm documents t∆∞∆°ng t·ª± s·ª≠ d·ª•ng semantic similarity v·ªõi cosine similarity
        
        Args:
            query (str): C√¢u query t√¨m ki·∫øm
            top_k (int): S·ªë l∆∞·ª£ng k·∫øt qu·∫£ top tr·∫£ v·ªÅ
            user_id (str): L·ªçc theo user ID (t√πy ch·ªçn)
        
        Returns:
            list: Danh s√°ch documents t∆∞∆°ng t·ª± v·ªõi scores
        """
        try:
            # T·∫°o embedding cho query
            query_embedding = self.embeddings_model.embed_query(query)
            
            # X√¢y d·ª±ng filter query
            filter_query = {}
            if user_id:
                filter_query["user_id"] = user_id
            
            # L·∫•y t·∫•t c·∫£ documents ph√π h·ª£p v·ªõi filter
            documents = list(self.collection.find(filter_query))
            
            if not documents:
                logger.info("üîç Kh√¥ng t√¨m th·∫•y documents n√†o ph√π h·ª£p v·ªõi filter")
                return []
            
            # T√≠nh cosine similarity cho m·ªói document
            similarities = []
            for doc in documents:
                if "embedding" in doc:
                    doc_embedding = doc["embedding"]
                    similarity = self._cosine_similarity(query_embedding, doc_embedding)
                    similarities.append((doc, similarity))
            
            # S·∫Øp x·∫øp theo similarity score (gi·∫£m d·∫ßn)
            similarities.sort(key=lambda x: x[1], reverse=True)
            
            # Tr·∫£ v·ªÅ top_k k·∫øt qu·∫£
            top_results = similarities[:top_k]
            
            # Format k·∫øt qu·∫£
            results = []
            for doc, score in top_results:
                result = {
                    "content": doc.get("content", ""),
                    "file_name": doc.get("file_name", ""),
                    "user_id": doc.get("user_id", ""),
                    "metadata": doc.get("metadata", {}),
                    "score": score
                }
                results.append(result)
            
            logger.info(f"üîç T√¨m th·∫•y {len(results)} documents t∆∞∆°ng t·ª± cho query: '{query}'")
            return results
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói trong semantic search: {e}")
            return []
    
    def _cosine_similarity(self, vec1, vec2):
        """
        T√≠nh cosine similarity gi·ªØa hai vectors
        
        Args:
            vec1 (list): Vector th·ª© nh·∫•t
            vec2 (list): Vector th·ª© hai
        
        Returns:
            float: Cosine similarity score (0-1)
        """
        try:
            # Chuy·ªÉn ƒë·ªïi sang numpy arrays
            vec1 = np.array(vec1)
            vec2 = np.array(vec2)
            
            # T√≠nh cosine similarity
            dot_product = np.dot(vec1, vec2)
            norm1 = np.linalg.norm(vec1)
            norm2 = np.linalg.norm(vec2)
            
            if norm1 == 0 or norm2 == 0:
                return 0.0
            
            similarity = dot_product / (norm1 * norm2)
            return float(similarity)
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi t√≠nh cosine similarity: {e}")
            return 0.0
    
    def get_user_documents(self, user_id, limit=20):
        """
        L·∫•y t·∫•t c·∫£ documents c·ªßa m·ªôt user c·ª• th·ªÉ
        
        Args:
            user_id (str): ID c·ªßa user
            limit (int): S·ªë l∆∞·ª£ng documents t·ªëi ƒëa
        
        Returns:
            list: Danh s√°ch documents c·ªßa user
        """
        try:
            documents = list(self.collection.find(
                {"user_id": user_id},
                {"content": 0, "embedding": 0}  # Lo·∫°i tr·ª´ c√°c tr∆∞·ªùng l·ªõn
            ).sort("created_at", -1).limit(limit))
            
            logger.info(f"üìÑ ƒê√£ l·∫•y {len(documents)} documents c·ªßa user: {user_id}")
            return documents
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi l·∫•y documents c·ªßa user: {e}")
            return []
    
    def delete_document(self, doc_id, user_id=None):
        """
        X√≥a m·ªôt document
        
        Args:
            doc_id (str): ID c·ªßa document c·∫ßn x√≥a
            user_id (str): ID c·ªßa user ƒë·ªÉ x√°c minh (t√πy ch·ªçn)
        
        Returns:
            bool: True n·∫øu th√†nh c√¥ng
        """
        try:
            filter_query = {"_id": self._parse_object_id(doc_id)}
            if user_id:
                filter_query["user_id"] = user_id
            
            result = self.collection.delete_one(filter_query)
            
            if result.deleted_count > 0:
                logger.info(f"‚úÖ Document {doc_id} ƒë√£ ƒë∆∞·ª£c x√≥a th√†nh c√¥ng")
                return True
            else:
                logger.warning(f"‚ö†Ô∏è Document {doc_id} kh√¥ng t√¨m th·∫•y ho·∫∑c kh√¥ng ƒë∆∞·ª£c ph√©p")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi x√≥a document: {e}")
            return False
    
    def _get_current_timestamp(self):
        """L·∫•y timestamp hi·ªán t·∫°i"""
        from datetime import datetime
        return datetime.utcnow()
    
    def _parse_object_id(self, doc_id):
        """Chuy·ªÉn ƒë·ªïi string ID th√†nh ObjectId"""
        from bson import ObjectId
        try:
            return ObjectId(doc_id)
        except:
            return doc_id
    
    def close_connection(self):
        """ƒê√≥ng k·∫øt n·ªëi MongoDB"""
        if self.client:
            self.client.close()
            logger.info("üîí ƒê√£ ƒë√≥ng k·∫øt n·ªëi MongoDB")

# Demo function ƒë·ªÉ test SemanticDocumentManager
def demo_semantic_search():
    """Demo c√°c thao t√°c semantic document"""
    try:
        print("üöÄ Demo Semantic Document Manager")
        print("=" * 50)
        
        # Kh·ªüi t·∫°o semantic document manager
        semantic_manager = SemanticDocumentManager()
        
        # Test 1: L∆∞u sample documents
        print("\nüìù Test 1: L∆∞u sample documents...")
        
        doc1_id = semantic_manager.save_document(
            "user1", 
            "hoc_toan.pdf",
            "ƒê·ªãnh l√Ω Pythagore: Trong tam gi√°c vu√¥ng, b√¨nh ph∆∞∆°ng c·∫°nh huy·ªÅn b·∫±ng t·ªïng b√¨nh ph∆∞∆°ng hai c·∫°nh g√≥c vu√¥ng. C√¥ng th·ª©c: a¬≤ + b¬≤ = c¬≤"
        )
        
        doc2_id = semantic_manager.save_document(
            "user1", 
            "hoc_vatly.pdf",
            "ƒê·ªãnh lu·∫≠t II Newton: L·ª±c b·∫±ng kh·ªëi l∆∞·ª£ng nh√¢n gia t·ªëc. C√¥ng th·ª©c: F = m √ó a. ƒê∆°n v·ªã l·ª±c l√† Newton (N)."
        )
        
        doc3_id = semantic_manager.save_document(
            "user1", 
            "hoc_hoa.pdf",
            "ƒê·ªãnh lu·∫≠t b·∫£o to√†n kh·ªëi l∆∞·ª£ng: Trong ph·∫£n ·ª©ng h√≥a h·ªçc, t·ªïng kh·ªëi l∆∞·ª£ng c√°c ch·∫•t tham gia b·∫±ng t·ªïng kh·ªëi l∆∞·ª£ng c√°c ch·∫•t t·∫°o th√†nh."
        )
        
        print(f"‚úÖ ƒê√£ l∆∞u 3 documents v·ªõi IDs: {doc1_id}, {doc2_id}, {doc3_id}")
        
        # Test 2: Semantic search
        print("\nüîç Test 2: Test semantic search...")
        
        # T√¨m ki·∫øm n·ªôi dung to√°n h·ªçc
        math_results = semantic_manager.search_similar("C√¥ng th·ª©c t√≠nh c·∫°nh huy·ªÅn l√† g√¨?", top_k=2)
        print(f"\nüîç T√¨m ki·∫øm: 'C√¥ng th·ª©c t√≠nh c·∫°nh huy·ªÅn l√† g√¨?'")
        for i, result in enumerate(math_results, 1):
            print(f"  {i}. File: {result.get('file_name', 'Unknown')}")
            print(f"     N·ªôi dung: {result.get('content', '')[:100]}...")
            print(f"     Score: {result.get('score', 'N/A')}")
        
        # T√¨m ki·∫øm n·ªôi dung v·∫≠t l√Ω
        physics_results = semantic_manager.search_similar("L·ª±c v√† gia t·ªëc c√≥ m·ªëi quan h·ªá g√¨?", top_k=2)
        print(f"\nüîç T√¨m ki·∫øm: 'L·ª±c v√† gia t·ªëc c√≥ m·ªëi quan h·ªá g√¨?'")
        for i, result in enumerate(physics_results, 1):
            print(f"  {i}. File: {result.get('file_name', 'Unknown')}")
            print(f"     N·ªôi dung: {result.get('content', '')[:100]}...")
            print(f"     Score: {result.get('score', 'N/A')}")
        
        # Test 3: L·∫•y documents c·ªßa user
        print("\nüìÑ Test 3: L·∫•y documents c·ªßa user...")
        user_docs = semantic_manager.get_user_documents("user1", limit=5)
        print(f"üìÅ User 'user1' c√≥ {len(user_docs)} documents:")
        for doc in user_docs:
            print(f"  - {doc.get('file_name', 'Unknown')} (t·∫°o l√∫c: {doc.get('created_at', 'Unknown')})")
        
        # Test 4: X√≥a document
        print("\nüóëÔ∏è Test 4: X√≥a document...")
        if semantic_manager.delete_document(doc3_id, "user1"):
            print(f"‚úÖ Document {doc3_id} ƒë√£ ƒë∆∞·ª£c x√≥a th√†nh c√¥ng")
        else:
            print(f"‚ùå Kh√¥ng th·ªÉ x√≥a document {doc3_id}")
        
        # ƒê√≥ng k·∫øt n·ªëi
        semantic_manager.close_connection()
        
        print("\nüéâ Demo semantic search ho√†n th√†nh th√†nh c√¥ng!")
        
    except Exception as e:
        print(f"‚ùå Demo semantic search th·∫•t b·∫°i: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    demo_semantic_search()
