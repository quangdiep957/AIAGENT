"""
Web Search Tool - Tool tÃ¬m kiáº¿m web vá»›i GPT-4.1 vÃ  Ä‘Ã¡nh giÃ¡ káº¿t quáº£
"""

from langchain.tools import tool
from langchain_openai import ChatOpenAI
import requests
from typing import Dict, Any, List
import json
import time
from datetime import datetime

class WebSearchTool:
    """Tool tÃ¬m kiáº¿m web vá»›i GPT-4.1"""
    
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4.1", temperature=0.2)
        self.search_engines = {
            "duckduckgo": "https://api.duckduckgo.com/",
            "searx": "https://searx.space/search"  # Public instance
        }
    
    def search_duckduckgo(self, query: str, max_results: int = 5) -> List[Dict]:
        """TÃ¬m kiáº¿m qua DuckDuckGo API"""
        try:
            params = {
                'q': query,
                'format': 'json',
                'no_html': '1',
                'skip_disambig': '1'
            }
            
            response = requests.get(
                "https://api.duckduckgo.com/",
                params=params,
                timeout=10
            )
            
            if response.status_code == 200:
                data = response.json()
                results = []
                
                # Láº¥y káº¿t quáº£ tá»« RelatedTopics
                if 'RelatedTopics' in data:
                    for topic in data['RelatedTopics'][:max_results]:
                        if isinstance(topic, dict) and 'Text' in topic:
                            results.append({
                                'title': topic.get('Text', '')[:100],
                                'content': topic.get('Text', ''),
                                'url': topic.get('FirstURL', ''),
                                'source': 'DuckDuckGo'
                            })
                
                # Náº¿u khÃ´ng cÃ³ RelatedTopics, dÃ¹ng Abstract
                if not results and 'Abstract' in data and data['Abstract']:
                    results.append({
                        'title': data.get('Heading', 'Search Result'),
                        'content': data['Abstract'],
                        'url': data.get('AbstractURL', ''),
                        'source': 'DuckDuckGo'
                    })
                
                return results
            
        except Exception as e:
            print(f"DuckDuckGo search error: {e}")
        
        return []
    
    def search_with_llm_fallback(self, query: str) -> List[Dict]:
        """TÃ¬m kiáº¿m vá»›i LLM fallback khi API khÃ´ng kháº£ dá»¥ng"""
        try:
            # Thá»­ tÃ¬m kiáº¿m qua API trÆ°á»›c
            results = self.search_duckduckgo(query)
            
            if results:
                return results
            
            # Fallback: DÃ¹ng LLM Ä‘á»ƒ táº¡o ná»™i dung dá»±a trÃªn kiáº¿n thá»©c
            llm_prompt = f"""
            NgÆ°á»i dÃ¹ng tÃ¬m kiáº¿m: "{query}"
            
            VÃ¬ khÃ´ng tÃ¬m tháº¥y káº¿t quáº£ web search, hÃ£y cung cáº¥p thÃ´ng tin há»¯u Ã­ch dá»±a trÃªn kiáº¿n thá»©c cá»§a báº¡n.
            Táº­p trung vÃ o giÃ¡o dá»¥c tiáº¿ng Anh vÃ  há»c táº­p.
            
            Tráº£ vá» JSON format:
            {{
                "title": "TiÃªu Ä‘á» thÃ´ng tin",
                "content": "Ná»™i dung chi tiáº¿t (tiáº¿ng Viá»‡t + English examples náº¿u cÃ³)",
                "source": "GPT-4.1 Knowledge",
                "relevance": "high/medium/low"
            }}
            """
            
            llm_response = self.llm.invoke(llm_prompt)
            
            try:
                # Parse JSON tá»« LLM response
                import re
                json_match = re.search(r'\{.*\}', llm_response.content, re.DOTALL)
                if json_match:
                    result_data = json.loads(json_match.group())
                    return [{
                        'title': result_data.get('title', 'Knowledge Base Result'),
                        'content': result_data.get('content', llm_response.content),
                        'url': '',
                        'source': 'GPT-4.1 Knowledge',
                        'relevance': result_data.get('relevance', 'medium')
                    }]
            except:
                # Náº¿u khÃ´ng parse Ä‘Æ°á»£c JSON, dÃ¹ng raw content
                return [{
                    'title': f'ThÃ´ng tin vá»: {query}',
                    'content': llm_response.content,
                    'url': '',
                    'source': 'GPT-4.1 Knowledge',
                    'relevance': 'medium'
                }]
                
        except Exception as e:
            return [{
                'title': 'Lá»—i tÃ¬m kiáº¿m',
                'content': f'KhÃ´ng thá»ƒ tÃ¬m kiáº¿m thÃ´ng tin vá» "{query}". Lá»—i: {str(e)}',
                'url': '',
                'source': 'Error',
                'relevance': 'low'
            }]
    
    def evaluate_search_results(self, query: str, results: List[Dict]) -> Dict[str, Any]:
        """ÄÃ¡nh giÃ¡ káº¿t quáº£ tÃ¬m kiáº¿m báº±ng LLM"""
        try:
            if not results:
                return {
                    "is_relevant": False,
                    "quality_score": 0,
                    "summary": "KhÃ´ng tÃ¬m tháº¥y káº¿t quáº£ nÃ o",
                    "recommendation": "llm_response"
                }
            
            # Táº¡o prompt Ä‘Ã¡nh giÃ¡
            results_text = "\n\n".join([
                f"Káº¿t quáº£ {i+1}:\nTiÃªu Ä‘á»: {r['title']}\nNá»™i dung: {r['content'][:300]}..."
                for i, r in enumerate(results[:3])
            ])
            
            evaluation_prompt = f"""
            CÃ¢u há»i gá»‘c: "{query}"
            
            Káº¿t quáº£ tÃ¬m kiáº¿m:
            {results_text}
            
            HÃ£y Ä‘Ã¡nh giÃ¡:
            1. CÃ¡c káº¿t quáº£ cÃ³ liÃªn quan Ä‘áº¿n cÃ¢u há»i khÃ´ng?
            2. Cháº¥t lÆ°á»£ng thÃ´ng tin (1-10)
            3. CÃ³ Ä‘á»§ thÃ´ng tin Ä‘á»ƒ tráº£ lá»i khÃ´ng?
            
            Tráº£ vá» JSON:
            {{
                "is_relevant": true/false,
                "quality_score": 1-10,
                "summary": "TÃ³m táº¯t ngáº¯n gá»n vá» káº¿t quáº£",
                "recommendation": "use_search" hoáº·c "llm_response"
            }}
            
            LÆ°u Ã½: Náº¿u káº¿t quáº£ tá»‘t vÃ  liÃªn quan, chá»n "use_search". Náº¿u khÃ´ng Ä‘á»§ tá»‘t, chá»n "llm_response".
            """
            
            evaluation = self.llm.invoke(evaluation_prompt)
            
            try:
                # Parse JSON tá»« evaluation
                import re
                json_match = re.search(r'\{.*\}', evaluation.content, re.DOTALL)
                if json_match:
                    eval_data = json.loads(json_match.group())
                    return eval_data
            except:
                pass
            
            # Fallback evaluation
            return {
                "is_relevant": len(results) > 0,
                "quality_score": 5,
                "summary": f"TÃ¬m tháº¥y {len(results)} káº¿t quáº£",
                "recommendation": "use_search" if results else "llm_response"
            }
            
        except Exception as e:
            return {
                "is_relevant": False,
                "quality_score": 0,
                "summary": f"Lá»—i Ä‘Ã¡nh giÃ¡: {str(e)}",
                "recommendation": "llm_response"
            }

# Khá»Ÿi táº¡o tool instance
web_search_tool = WebSearchTool()

@tool
def search_web_with_evaluation(query: str) -> str:
    """
    TÃ¬m kiáº¿m thÃ´ng tin trÃªn web khi knowledge base khÃ´ng cÃ³, sau Ä‘Ã³ Ä‘Ã¡nh giÃ¡ káº¿t quáº£
    
    Args:
        query: CÃ¢u há»i hoáº·c tá»« khÃ³a cáº§n tÃ¬m kiáº¿m
    
    Returns:
        Káº¿t quáº£ tÃ¬m kiáº¿m Ä‘Ã£ Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ hoáº·c gá»£i Ã½ sá»­ dá»¥ng LLM
    """
    try:
        # BÆ°á»›c 1: TÃ¬m kiáº¿m web
        search_results = web_search_tool.search_with_llm_fallback(query)
        
        if not search_results:
            return """ğŸŒ **KhÃ´ng tÃ¬m tháº¥y káº¿t quáº£ web**

âŒ KhÃ´ng cÃ³ thÃ´ng tin tá»« tÃ¬m kiáº¿m web
ğŸ’¡ **Gá»£i Ã½:** LLM sáº½ tráº£ lá»i dá»±a trÃªn kiáº¿n thá»©c cÃ³ sáºµn

**Tráº¡ng thÃ¡i:** llm_response_needed"""
        
        # BÆ°á»›c 2: ÄÃ¡nh giÃ¡ káº¿t quáº£
        evaluation = web_search_tool.evaluate_search_results(query, search_results)
        
        # BÆ°á»›c 3: Quyáº¿t Ä‘á»‹nh response
        if evaluation.get("recommendation") == "use_search" and evaluation.get("quality_score", 0) >= 6:
            # Káº¿t quáº£ tá»‘t, hiá»ƒn thá»‹ search results
            formatted_results = []
            for i, result in enumerate(search_results[:3], 1):
                formatted_results.append(f"""
ğŸ” **Káº¿t quáº£ {i}**
ğŸ“ **TiÃªu Ä‘á»:** {result['title']}
ğŸŒ **Nguá»“n:** {result['source']}
ğŸ“„ **Ná»™i dung:** {result['content'][:400]}{'...' if len(result['content']) > 400 else ''}
{f"ğŸ”— **Link:** {result['url']}" if result['url'] else ''}
""")
            
            return f"""ğŸŒ **Káº¿t quáº£ tÃ¬m kiáº¿m web**

ğŸ“Š **ÄÃ¡nh giÃ¡:** {evaluation['summary']}
â­ **Cháº¥t lÆ°á»£ng:** {evaluation['quality_score']}/10

{''.join(formatted_results)}

ğŸ’¡ **Dá»±a trÃªn káº¿t quáº£ trÃªn, tÃ´i cÃ³ thá»ƒ giÃºp báº¡n tráº£ lá»i cÃ¢u há»i chi tiáº¿t hÆ¡n.**
**Tráº¡ng thÃ¡i:** search_results_ready"""
        
        else:
            # Káº¿t quáº£ khÃ´ng tá»‘t, gá»£i Ã½ dÃ¹ng LLM
            return f"""ğŸŒ **Káº¿t quáº£ tÃ¬m kiáº¿m web khÃ´ng Ä‘áº¡t yÃªu cáº§u**

ğŸ“Š **ÄÃ¡nh giÃ¡:** {evaluation['summary']}
â­ **Cháº¥t lÆ°á»£ng:** {evaluation['quality_score']}/10

âŒ **LÃ½ do:** ThÃ´ng tin khÃ´ng Ä‘á»§ chÃ­nh xÃ¡c hoáº·c khÃ´ng liÃªn quan
ğŸ’¡ **Gá»£i Ã½:** LLM sáº½ tráº£ lá»i dá»±a trÃªn kiáº¿n thá»©c chuyÃªn mÃ´n

**Tráº¡ng thÃ¡i:** llm_response_needed"""
            
    except Exception as e:
        return f"""ğŸŒ **Lá»—i tÃ¬m kiáº¿m web**

âŒ **Lá»—i:** {str(e)}
ğŸ’¡ **Gá»£i Ã½:** LLM sáº½ tráº£ lá»i dá»±a trÃªn kiáº¿n thá»©c cÃ³ sáºµn

**Tráº¡ng thÃ¡i:** llm_response_needed"""

@tool
def generate_llm_response_for_query(query: str) -> str:
    """
    Táº¡o response báº±ng LLM khi web search khÃ´ng kháº£ dá»¥ng hoáº·c khÃ´ng phÃ¹ há»£p
    
    Args:
        query: CÃ¢u há»i cáº§n tráº£ lá»i
    
    Returns:
        Response tá»« LLM dá»±a trÃªn kiáº¿n thá»©c cÃ³ sáºµn
    """
    try:
        llm = ChatOpenAI(model="gpt-4.1", temperature=0.3)
        
        response_prompt = f"""
        CÃ¢u há»i: "{query}"
        
        Báº¡n lÃ  AI Tutor chuyÃªn vá» tiáº¿ng Anh. HÃ£y tráº£ lá»i cÃ¢u há»i trÃªn dá»±a trÃªn kiáº¿n thá»©c cá»§a báº¡n.
        
        Quy táº¯c:
        1. Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t Ä‘á»ƒ giáº£i thÃ­ch
        2. Giá»¯ nguyÃªn ná»™i dung tiáº¿ng Anh (examples, grammar rules) 
        3. Cung cáº¥p vÃ­ dá»¥ cá»¥ thá»ƒ
        4. Táº¡o bÃ i táº­p náº¿u phÃ¹ há»£p
        5. ÄÃ¡nh dáº¥u rÃµ Ä‘Ã¢y lÃ  response tá»« kiáº¿n thá»©c AI
        
        Format response:
        ğŸ¤– **AI Tutor Response**
        [Ná»™i dung tráº£ lá»i chi tiáº¿t]
        
        ğŸ’¡ *LÆ°u Ã½: ThÃ´ng tin nÃ y dá»±a trÃªn kiáº¿n thá»©c AI. Báº¡n cÃ³ thá»ƒ tham kháº£o thÃªm nguá»“n khÃ¡c.*
        """
        
        llm_response = llm.invoke(response_prompt)
        return llm_response.content
        
    except Exception as e:
        return f"""ğŸ¤– **AI Tutor Response**

Xin lá»—i, tÃ´i gáº·p lá»—i khi xá»­ lÃ½ cÃ¢u há»i: "{query}"

âŒ **Lá»—i:** {str(e)}

ğŸ’¡ **Gá»£i Ã½:** Báº¡n cÃ³ thá»ƒ:
- Diá»…n Ä‘áº¡t láº¡i cÃ¢u há»i
- Chia nhá» cÃ¢u há»i thÃ nh nhiá»u pháº§n
- Upload tÃ i liá»‡u liÃªn quan Ä‘á»ƒ tÃ´i cÃ³ thÃªm ngá»¯ cáº£nh

*LÆ°u Ã½: ÄÃ¢y lÃ  response tá»± Ä‘á»™ng tá»« AI Tutor.*"""
